{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4-5(Deep Learning).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muratkakun/Machine-Learning/blob/master/HW4_5(Deep_Learning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pCVmkCzCtYW",
        "colab_type": "text"
      },
      "source": [
        "# HW4-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHYGzIkCyJVD",
        "colab_type": "text"
      },
      "source": [
        "## 1) Load and plot few example in MNIST-CLUTTERED. (It is MNIST on cluttered bg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLAw5sbhCz7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "b = np.load('mnist_cluttered_60x60_6distortions_test_only.npz', 'r')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGtlRzYqFUKD",
        "colab_type": "code",
        "outputId": "952ed3c4-c128-474e-ef74-d2791d2bf1e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(b.files)\n",
        "arr = b['y']\n",
        "print(arr.shape)\n",
        "print(arr)\n",
        "print(arr[arr==1])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['x', 'y']\n",
            "(10000,)\n",
            "[3 9 4 ... 6 3 5]\n",
            "[1 1 1 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0CKLXNHyBcR",
        "colab_type": "text"
      },
      "source": [
        "Divide data into train and test splits. Make sure all labels are represented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkGN2kTT_FLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "outputId": "904880ec-c841-4ad9-c703-aa625d96e276"
      },
      "source": [
        "import tensorflow as tf\n",
        "x_all = b['x']\n",
        "y_all = b['y']\n",
        "x_train = x_all[0:500:1]\n",
        "y_train = y_all[0:500:1]\n",
        "x_test = x_all[500:1000:1]\n",
        "y_test = y_all[500:1000:1]\n",
        "\n",
        "print(x_train)\n",
        "print(y_train)\n",
        "\n",
        "print(x_test)\n",
        "print(y_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[3 9 4 0 6 1 8 6 1 7 9 9 8 6 3 6 3 4 7 4 4 0 5 9 0 5 5 8 5 2 1 5 4 1 9 1 3\n",
            " 2 0 0 3 2 0 2 9 9 7 1 6 5 8 8 1 2 4 1 8 2 8 1 9 5 9 8 8 1 5 2 9 0 5 6 6 9\n",
            " 6 1 3 0 1 1 5 1 2 7 1 9 1 7 2 7 6 0 5 7 7 4 4 4 1 1 6 6 1 3 7 8 6 9 8 5 5\n",
            " 8 1 5 8 5 9 2 0 5 4 4 7 9 2 8 8 8 5 4 1 2 5 6 5 9 3 4 8 2 7 4 3 5 9 0 7 3\n",
            " 1 9 5 8 7 6 9 3 0 0 3 2 4 6 5 5 6 8 7 7 1 0 5 0 8 3 1 1 6 2 0 7 0 1 3 5 0\n",
            " 8 9 1 4 1 1 5 7 9 4 5 9 9 8 9 6 1 4 6 0 0 4 6 8 1 8 1 6 7 5 2 2 2 3 7 1 4\n",
            " 0 9 9 2 0 4 6 9 1 2 3 6 6 1 2 6 5 9 3 6 0 2 3 6 8 9 2 6 4 8 6 1 1 0 6 3 7\n",
            " 8 2 0 4 8 9 4 5 6 7 4 3 1 5 7 4 1 5 1 4 4 0 8 6 3 7 8 7 2 0 1 4 1 6 0 0 7\n",
            " 8 7 1 2 3 7 6 8 0 8 4 1 5 0 7 8 4 3 6 1 2 1 3 6 1 9 2 4 9 0 3 6 9 3 7 6 8\n",
            " 1 6 0 3 0 1 7 6 1 3 9 0 1 0 9 1 3 2 3 9 9 2 0 6 6 5 9 2 4 7 4 6 4 3 6 5 8\n",
            " 6 9 3 7 9 2 0 2 8 4 1 7 9 5 1 2 8 2 9 2 8 3 0 9 3 0 2 5 7 6 4 8 7 9 4 0 7\n",
            " 6 2 0 5 3 5 9 4 4 0 5 4 8 4 3 6 5 6 7 7 4 9 8 6 5 1 4 9 7 3 9 9 0 3 7 7 8\n",
            " 5 7 8 1 8 0 1 7 0 4 7 0 7 0 3 2 7 0 6 1 3 8 9 7 8 4 4 8 0 7 4 2 3 0 1 2 8\n",
            " 1 8 6 2 7 1 6 7 4 8 2 7 9 7 4 7 7 5 4]\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[7 7 4 7 1 1 9 0 9 0 9 6 0 7 3 4 1 9 7 5 7 1 8 3 8 6 7 0 2 5 5 9 3 8 9 4 3\n",
            " 2 4 4 0 5 5 7 0 0 3 9 7 9 6 7 4 7 7 7 7 1 5 3 0 2 4 3 7 2 7 0 4 0 1 3 8 0\n",
            " 4 8 9 5 0 5 7 6 5 6 3 3 1 1 3 6 4 0 4 5 1 8 4 3 8 2 2 2 3 0 3 7 3 2 8 3 4\n",
            " 5 1 6 6 9 0 5 9 8 8 3 9 7 3 5 7 6 6 5 4 5 6 4 7 1 8 4 8 8 5 0 8 4 9 3 6 2\n",
            " 1 8 1 2 8 5 5 8 3 6 0 0 3 0 6 1 1 2 3 5 2 3 7 9 0 8 7 0 9 7 1 0 3 9 9 2 7\n",
            " 9 8 5 7 3 5 6 1 8 9 4 2 7 7 2 3 4 1 3 3 4 6 6 8 0 6 0 3 9 0 1 4 2 8 2 1 9\n",
            " 7 8 3 8 1 1 1 2 7 8 4 9 0 1 1 5 2 5 5 4 2 0 2 6 7 5 5 7 4 0 9 3 4 0 8 0 9\n",
            " 2 5 0 6 8 2 9 4 1 2 3 1 8 9 2 1 6 2 4 4 4 6 5 4 0 8 4 3 9 9 8 1 6 9 1 7 6\n",
            " 7 8 5 7 8 1 7 1 0 4 2 1 3 2 6 5 4 0 1 1 2 7 7 0 6 9 7 1 2 9 5 6 8 1 0 8 6\n",
            " 9 2 2 5 2 9 0 8 8 5 7 5 4 6 9 1 7 3 3 2 4 0 9 8 6 3 0 4 8 2 1 9 4 5 7 2 1\n",
            " 0 3 4 3 3 9 0 7 6 0 2 6 5 0 5 3 1 6 7 0 1 1 0 0 0 2 6 2 3 4 6 1 7 7 7 1 1\n",
            " 3 5 2 4 6 8 0 1 4 4 2 0 1 8 9 2 8 1 9 6 2 8 8 6 3 9 9 3 7 1 1 6 5 6 7 0 1\n",
            " 4 2 5 8 8 4 2 7 8 4 5 7 4 0 3 4 5 7 8 3 9 3 6 0 1 3 8 4 5 1 3 5 2 9 4 4 6\n",
            " 8 3 6 4 3 5 4 4 2 5 7 2 9 1 6 4 5 3 1]\n",
            "(500, 3600)\n",
            "(500, 3600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktBmFVSkyZ13",
        "colab_type": "text"
      },
      "source": [
        "## 2) Create a 2-hidden layer network. (Input-800-800-Output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQBXSTckNjX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2d269a9-c3e2-4f8c-c38c-6daf543298c9"
      },
      "source": [
        "feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(x_train)\n",
        "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[800, 800], n_classes=10, feature_columns=feature_columns)\n",
        "dnn_clf.fit(x=x_train, y=y_train, batch_size=50, steps=1000)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-eb7b8cb4e463>:1: infer_real_valued_columns_from_input (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:143: setup_train_data_feeder (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:96: extract_dask_data (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please feed input to tf.data to support dask.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:100: extract_pandas_data (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:159: DataFeeder.__init__ (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tensorflow/transform or tf.data.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:340: check_array (from tensorflow.contrib.learn.python.learn.learn_io.data_feeder) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please convert numpy dtypes explicitly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:183: infer_real_valued_columns_from_input_fn (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please specify feature columns explicitly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.contrib.estimator.*_head.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:427: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmps66w42pu\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f25d2e5dc18>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmps66w42pu', '_session_creation_timeout_secs': 7200}\n",
            "WARNING:tensorflow:From <ipython-input-11-eb7b8cb4e463>:3: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
            "Instructions for updating:\n",
            "Estimator is decoupled from Scikit Learn interface by moving into\n",
            "separate class SKCompat. Arguments x, y and batch_size are only\n",
            "available in the SKCompat class, Estimator will only accept input_fn.\n",
            "Example conversion:\n",
            "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
            "WARNING:tensorflow:From <ipython-input-11-eb7b8cb4e463>:3: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
            "Instructions for updating:\n",
            "Estimator is decoupled from Scikit Learn interface by moving into\n",
            "separate class SKCompat. Arguments x, y and batch_size are only\n",
            "available in the SKCompat class, Estimator will only accept input_fn.\n",
            "Example conversion:\n",
            "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
            "WARNING:tensorflow:From <ipython-input-11-eb7b8cb4e463>:3: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
            "Instructions for updating:\n",
            "Estimator is decoupled from Scikit Learn interface by moving into\n",
            "separate class SKCompat. Arguments x, y and batch_size are only\n",
            "available in the SKCompat class, Estimator will only accept input_fn.\n",
            "Example conversion:\n",
            "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py:508: SKCompat.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to the Estimator interface.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:98: extract_dask_labels (from tensorflow.contrib.learn.python.learn.learn_io.dask_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please feed input to tf.data to support dask.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/learn_io/data_feeder.py:102: extract_pandas_labels (from tensorflow.contrib.learn.python.learn.learn_io.pandas_io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please access pandas data directly.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmps66w42pu/model.ckpt.\n",
            "INFO:tensorflow:loss = 2.3062181, step = 1\n",
            "INFO:tensorflow:global_step/sec: 37.2013\n",
            "INFO:tensorflow:loss = 0.08703038, step = 101 (2.689 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.6457\n",
            "INFO:tensorflow:loss = 0.015329731, step = 201 (2.889 sec)\n",
            "INFO:tensorflow:global_step/sec: 37.3354\n",
            "INFO:tensorflow:loss = 0.009061858, step = 301 (2.676 sec)\n",
            "INFO:tensorflow:global_step/sec: 35.94\n",
            "INFO:tensorflow:loss = 0.0052167354, step = 401 (2.783 sec)\n",
            "INFO:tensorflow:global_step/sec: 32.9278\n",
            "INFO:tensorflow:loss = 0.004028795, step = 501 (3.041 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.8505\n",
            "INFO:tensorflow:loss = 0.0031408905, step = 601 (2.865 sec)\n",
            "INFO:tensorflow:global_step/sec: 38.2232\n",
            "INFO:tensorflow:loss = 0.0025378054, step = 701 (2.619 sec)\n",
            "INFO:tensorflow:global_step/sec: 32.2998\n",
            "INFO:tensorflow:loss = 0.0020291077, step = 801 (3.093 sec)\n",
            "INFO:tensorflow:global_step/sec: 30.834\n",
            "INFO:tensorflow:loss = 0.0018708084, step = 901 (3.248 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmps66w42pu/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.0016170244.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DNNClassifier(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x7f260f4b1278>, 'hidden_units': [800, 800], 'feature_columns': (_RealValuedColumn(column_name='', dimension=3600, default_value=None, dtype=tf.float32, normalizer=None),), 'optimizer': None, 'activation_fn': <function relu at 0x7f25de2aeea0>, 'dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bpTuhCmynda",
        "colab_type": "text"
      },
      "source": [
        "##3) Train and test the performance.  (The accuracy can be 60% 70%). \n",
        "\n",
        "10-20 epochs is OK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0BtiYDxM4ym",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "55c3523f-a9f8-44e5-e9af-733c5f3bd3b6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = list(dnn_clf.predict(x_test))\n",
        "accuracy_score(y_test, y_pred)\n",
        "#dnn_clf.evaluate(x_test, y_test)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmps66w42pu/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugoJwGtZy_In",
        "colab_type": "text"
      },
      "source": [
        "## 4) Compare activation functions. Plot validation accuracy for RELU, ELU, TANH, SELU. \n",
        "### Note that each has its own initialization system. For RELU use he_normal or uniform, elu use he_normal, tanh use glorot_uniform, selu use lecun_normal\n",
        "\n",
        "Comment on the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT9sbQl3zIjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8woM43s_9KOw",
        "colab_type": "text"
      },
      "source": [
        "##5) For the best and second performing activation repeat all the tests with  SGD, SGD+momentum, SGD+Nesterov, RMSRPOB Adam\n",
        "\n",
        "Comment on the results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8ED2Dno9ec2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTk7666m9glk",
        "colab_type": "text"
      },
      "source": [
        "##6) With the best performing model use Batchnorm and test again\n",
        "\n",
        "Comment on the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITynDHCY9qtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph2Yi1bK9rsl",
        "colab_type": "text"
      },
      "source": [
        "##7) With the best performing add Dropout between layers and test again\n",
        "\n",
        "Comment on the result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVt4KRNl9wPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMC1OyM39wuK",
        "colab_type": "text"
      },
      "source": [
        "##8) With the Dropout version, apply MonteCarlo Dropout.\n",
        "\n",
        "Comment on the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0V5jug-91LD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jwr6nF291VP",
        "colab_type": "text"
      },
      "source": [
        "##9) Compare LR rate scheduling mehtods.   \n",
        "###a) fix learning rate, \n",
        "###b) decaying learning rate (choose one)\n",
        "###c) 1cycle schedule choose your n0, n1"
      ]
    }
  ]
}